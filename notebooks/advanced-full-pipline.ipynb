{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport polars as pl\nimport gc\nimport os\nimport joblib \nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom xgboost.callback import EarlyStopping\nfrom catboost import CatBoostRegressor\nimport kaggle_evaluation.jane_street_inference_server\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:03.466316Z","iopub.execute_input":"2025-12-23T18:05:03.466883Z","iopub.status.idle":"2025-12-23T18:05:12.003177Z","shell.execute_reply.started":"2025-12-23T18:05:03.466858Z","shell.execute_reply":"2025-12-23T18:05:12.002559Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ============================\n# Reduce Memory Usage Function\n# ============================\ndef reduce_memory_usage(df,float16_as32=False):\n    start_mem = df.memory_usage().sum()/1024**2\n    print(f'df memory usage before reduce : {start_mem} MB')\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        # Skip non-numeric columns\n        if col_type.kind not in ['i','f']:\n            continue\n        \n        c_min = df[col].min()\n        c_max = df[col].max()\n\n        # Integer types\n        if col_type.kind in ['i']:\n            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n            else:\n                df[col] = df[col].astype(np.int64)\n\n        # Float types\n        else:\n            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float32 if float16_as32 else np.float16)\n            elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n        \n    end_mem = df.memory_usage().sum()/1024**2\n    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n    print(f\"Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:15.438306Z","iopub.execute_input":"2025-12-23T18:05:15.439296Z","iopub.status.idle":"2025-12-23T18:05:15.447466Z","shell.execute_reply.started":"2025-12-23T18:05:15.439266Z","shell.execute_reply":"2025-12-23T18:05:15.446661Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# -------------------------------------------\n# Custom Weighted Zero-Mean R² for Lgb Model\n# ------------------------------------------\ndef weighted_zero_mean_r2_lgb(y_true, y_pred, sample_weight):\n    y_true_zm = y_true - np.average(y_true, weights=sample_weight)\n    y_pred_zm = y_pred - np.average(y_pred, weights=sample_weight)\n\n    numerator = np.sum(sample_weight * (y_true_zm - y_pred_zm) ** 2)\n    denominator = np.sum(sample_weight * (y_true_zm) ** 2)\n\n    r2 = 1 - numerator / (denominator + 1e-38)\n    return \"weighted_zero_mean_r2\", r2, True   # maximize=True\n# -------------------------------------------\n# Custom Weighted Zero-Mean R² for Xgb Model\n# -------------------------------------------\ndef weighted_zero_mean_r2_xgb(y_true, y_pred, sample_weight):\n    y_true_zm = y_true - np.average(y_true, weights=sample_weight)\n    y_pred_zm = y_pred - np.average(y_pred, weights=sample_weight)\n    \n    numerator = np.sum(sample_weight * (y_true_zm - y_pred_zm)**2)\n    denominator = np.sum(sample_weight * (y_true_zm)**2)\n    \n    r2 = 1 - numerator / (denominator + 1e-38)\n    return r2        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:18.865175Z","iopub.execute_input":"2025-12-23T18:05:18.865836Z","iopub.status.idle":"2025-12-23T18:05:18.871006Z","shell.execute_reply.started":"2025-12-23T18:05:18.865812Z","shell.execute_reply":"2025-12-23T18:05:18.870334Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================\n#  Model Dictionary\n# ============================\nmodel_dict = {\n    \"LightGBM\": lambda:LGBMRegressor(\n    n_estimators=2000,\n    learning_rate=0.01,\n    num_leaves=50,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    random_state=42,\n    max_bin=128,\n    device=\"gpu\"\n    ),\n\n    \"XGBoost\": lambda: XGBRegressor(\n    n_estimators=2000,\n    learning_rate=0.01,\n    max_depth=6,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    objective=\"reg:squarederror\",\n    device=\"cuda\",\n    tree_method=\"gpu_hist\",\n    max_bin=128,\n    random_state=42,\n    eval_metric=weighted_zero_mean_r2_xgb,\n    disable_default_eval_metric=True\n    ),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:21.841126Z","iopub.execute_input":"2025-12-23T18:05:21.841991Z","iopub.status.idle":"2025-12-23T18:05:21.846787Z","shell.execute_reply.started":"2025-12-23T18:05:21.841956Z","shell.execute_reply":"2025-12-23T18:05:21.846062Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# use the Kaggle input directory\ntrain_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\n\n# Responders_Columns\nfeatures_cols = [f\"feature_{i:02d}\"for i in range(79)]\n\n# Define the target \ntarget = 'responder_6'\n\n#  Create models directory \nos.makedirs(\"models\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:24.842938Z","iopub.execute_input":"2025-12-23T18:05:24.843655Z","iopub.status.idle":"2025-12-23T18:05:24.847502Z","shell.execute_reply.started":"2025-12-23T18:05:24.843627Z","shell.execute_reply":"2025-12-23T18:05:24.846818Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Preapare Valid_df","metadata":{}},{"cell_type":"code","source":"# prepare valid_df\nskip_dates= 1499  # I will use last 200 days for validation\nvalid_df = pd.read_parquet(train_path, filters=[('date_id','>=', skip_dates)])\nvalid_df = reduce_memory_usage(valid_df)\n\n# X,y,w \nX_valid = valid_df[features_cols + ['time_id']]\ny_valid = valid_df[target]\nw_valid = valid_df[\"weight\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T18:05:27.753235Z","iopub.execute_input":"2025-12-23T18:05:27.753782Z","iopub.status.idle":"2025-12-23T18:05:39.791317Z","shell.execute_reply.started":"2025-12-23T18:05:27.753757Z","shell.execute_reply":"2025-12-23T18:05:39.790680Z"}},"outputs":[{"name":"stdout","text":"df memory usage before reduce : 2510.1318740844727 MB\nMemory usage after optimization is: 1290.52 MB\nDecreased by 48.6%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Prepare train data & Train models","metadata":{}},{"cell_type":"code","source":"START_TRAIN = 1099\nEND_TRAIN   = 1299\nfolds = 2\n\nmodels = []\n\nfor i in range(folds):\n    print(f'Load train data and apply reduce memory function on Fold {i+1}')\n   # load train data\n    train_df = pd.read_parquet(\n        train_path,\n        filters=[[('date_id', '>=', START_TRAIN),\n                  ('date_id', '<', END_TRAIN)]]\n    )\n    train_df = reduce_memory_usage(train_df)\n\n    # X,y,w\n    X_train = train_df[features_cols + ['time_id']]\n    y_train = (\n        train_df[target]\n        + 0.5 * train_df['responder_7']\n        + 0.5 * train_df['responder_8']\n    )\n    w_train = train_df[\"weight\"]\n    \n    print(f\"\\n================ Fold {i+1}/{folds} ================\")\n    print(f\"Train dates: from day {train_df['date_id'].min()} to {train_df['date_id'].max()} ({train_df['date_id'].nunique()} days)\")\n\n    # Train and evulate models\n    for model_name, model_class in model_dict.items():\n\n        print(f'\\n============== {model_name} | Fold {i+1} =========')\n\n        model = model_class()\n\n        if model_name == \"LightGBM\":\n\n            model.fit(\n                X_train, y_train,\n                sample_weight=w_train,\n                eval_set=[(X_valid, y_valid)],\n                eval_sample_weight=[w_valid],\n                eval_metric=weighted_zero_mean_r2_lgb,\n                callbacks=[lgb.early_stopping(100)]\n            )\n\n            print(\"Best iteration:\", model.best_iteration_)\n            print(\n                \"Best score:\",\n                model.best_score_['valid_0']['weighted_zero_mean_r2']\n            )\n\n        else:  # XGBoost\n\n            model.fit(\n                X_train, y_train,\n                sample_weight=w_train,\n                eval_set=[(X_valid, y_valid)],\n                sample_weight_eval_set=[w_valid],\n                callbacks=[EarlyStopping(rounds=100, maximize=True, save_best=True)],\n                verbose=20\n            )\n\n            print(f\"Best iteration: {model.best_iteration}\")\n            print(f\"Best CV score: {model.best_score}\\n\")\n\n        joblib.dump(model, f\"models/{model_name}_{i+1}.model\")\n        models.append((model_name, i+1, model))\n\n        del model\n        gc.collect()\n\n    del train_df, X_train, y_train, w_train\n    gc.collect()\n\n    if folds > 1 :\n        START_TRAIN += 200\n        END_TRAIN   += 200\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}