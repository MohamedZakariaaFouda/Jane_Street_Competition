{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport polars as pl\nimport gc\nimport os\nimport joblib \nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport kaggle_evaluation.jane_street_inference_server as inference_server","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:10.961311Z","iopub.execute_input":"2025-12-01T17:11:10.961584Z","iopub.status.idle":"2025-12-01T17:11:20.352270Z","shell.execute_reply.started":"2025-12-01T17:11:10.961563Z","shell.execute_reply":"2025-12-01T17:11:20.351711Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# use the Kaggle input directory\ntrain_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\n\n# Define the feature names based on the number of features (79 in this case)\nfeatures_names = [f\"feature_{i:02d}\"for i in range(79)]\n\n# Define the target \ntarget = 'responder_6'\n\n# Skip_dates\nskip_dates = 1400","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:20.353519Z","iopub.execute_input":"2025-12-01T17:11:20.354006Z","iopub.status.idle":"2025-12-01T17:11:20.357744Z","shell.execute_reply.started":"2025-12-01T17:11:20.353985Z","shell.execute_reply":"2025-12-01T17:11:20.357097Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================\n# Reduce Memory Usage Function\n# ============================\ndef reduce_memory_usage(df,float16_as32=False):\n    start_mem = df.memory_usage().sum()/1024**2\n    print(f'df memory usage before reduce : {start_mem} MB')\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        # Skip non-numeric columns\n        if col_type.kind not in ['i','f']:\n            continue\n        \n        c_min = df[col].min()\n        c_max = df[col].max()\n\n        # Integer types\n        if col_type.kind in ['i']:\n            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n            else:\n                df[col] = df[col].astype(np.int64)\n\n        # Float types\n        else:\n            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float32 if float16_as32 else np.float16)\n            elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n        \n    end_mem = df.memory_usage().sum()/1024**2\n    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n    print(f\"Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:20.358514Z","iopub.execute_input":"2025-12-01T17:11:20.358743Z","iopub.status.idle":"2025-12-01T17:11:20.377074Z","shell.execute_reply.started":"2025-12-01T17:11:20.358715Z","shell.execute_reply":"2025-12-01T17:11:20.376549Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_parquet(train_path, filters=[('date_id','>=', skip_dates)])\ndf = reduce_memory_usage(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:20.378517Z","iopub.execute_input":"2025-12-01T17:11:20.379043Z","iopub.status.idle":"2025-12-01T17:11:34.762036Z","shell.execute_reply.started":"2025-12-01T17:11:20.379025Z","shell.execute_reply":"2025-12-01T17:11:34.761239Z"}},"outputs":[{"name":"stdout","text":"df memory usage before reduce : 3711.112632751465 MB\nMemory usage after optimization is: 1907.97 MB\nDecreased by 48.6%\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"START_TRAIN = 1500\nEND_TRAIN   = 1599\nVALID_START = 1650\nVALID_END   = 1698\nN_FOLDS     = 2\n\n# ===============================#\n#     LOAD DATA (Train + Final Valid)\n# ===============================#\ntrain_df = ( df[df[\"date_id\"].between(START_TRAIN, END_TRAIN)].sort_values(\"date_id\"))\n\nvalid_df = df[df[\"date_id\"].between(VALID_START, VALID_END)]\nX_valid = valid_df[features_names]\ny_valid = valid_df[\"responder_6\"]\nw_valid =  valid_df[\"weight\"]\n# ===============================#\n#     CREATE FOLDS FROM DATES\n# ===============================#\nall_dates = np.arange(START_TRAIN, END_TRAIN+1)\nfolds = np.array_split(all_dates, N_FOLDS)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:34.762829Z","iopub.execute_input":"2025-12-01T17:11:34.763066Z","iopub.status.idle":"2025-12-01T17:11:37.763801Z","shell.execute_reply.started":"2025-12-01T17:11:34.763039Z","shell.execute_reply":"2025-12-01T17:11:37.762985Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================\n#  Model Dictionary\n# ============================\nmodel_dict = {\n    \"LightGBM\": lambda: LGBMRegressor(n_estimators=50, learning_rate=0.1),\n    \"XGBoost\":  lambda: XGBRegressor(n_estimators=50, learning_rate=0.1,),\n    \"CatBoost\": lambda: CatBoostRegressor(iterations=50, learning_rate=0.1, verbose=False)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:37.764626Z","iopub.execute_input":"2025-12-01T17:11:37.764887Z","iopub.status.idle":"2025-12-01T17:11:37.768961Z","shell.execute_reply.started":"2025-12-01T17:11:37.764864Z","shell.execute_reply":"2025-12-01T17:11:37.768391Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================\n#  Create model directory\n# ============================\nos.makedirs(\"models\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:37.769705Z","iopub.execute_input":"2025-12-01T17:11:37.769929Z","iopub.status.idle":"2025-12-01T17:11:37.782487Z","shell.execute_reply.started":"2025-12-01T17:11:37.769904Z","shell.execute_reply":"2025-12-01T17:11:37.781989Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ===============================#\n#     LOOP THROUGH FOLDS\n# ===============================#\nmodels = []\n\nfor fold, train_dates in enumerate(folds, start=1):\n    print(f\"--------------------- Fold {fold}/{N_FOLDS} -------------------\")\n    print(f\"Train dates: from day {train_dates.min()} to {train_dates.max()} ({len(train_dates)} days)\")\n    print('-'*50)\n    \n    fold_df = train_df[train_df[\"date_id\"].isin(train_dates)]\n    X_train = fold_df[features_names]\n    y_train = fold_df[\"responder_6\"]\n    w_train = fold_df[\"weight\"]\n\n    \n    # IMPORTANT: create new model instance inside the fold\n    for model_name, model_class in model_dict.items():\n        \n        print(f'============== {model_name} with Fold {fold}/{N_FOLDS} =========')\n        # create NEW model object for THIS fold\n        model = model_class()\n        model.fit(X_train, y_train, sample_weight=w_train)\n        # Save model\n        joblib.dump(model, f\"models/{model_name}_{fold}.model\")\n        \n        models.append((model_name, fold, model))\n\n    del X_train, y_train, w_train\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:11:37.783115Z","iopub.execute_input":"2025-12-01T17:11:37.783443Z","iopub.status.idle":"2025-12-01T17:15:08.418159Z","shell.execute_reply.started":"2025-12-01T17:11:37.783423Z","shell.execute_reply":"2025-12-01T17:15:08.417538Z"}},"outputs":[{"name":"stdout","text":"--------------------- Fold 1/2 -------------------\nTrain dates: from day 1500 to 1549 (50 days)\n--------------------------------------------------\n============== LightGBM with Fold 1/2 =========\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.823490 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19236\n[LightGBM] [Info] Number of data points in the train set: 1862432, number of used features: 79\n[LightGBM] [Info] Start training from score -0.011091\n============== XGBoost with Fold 1/2 =========\n============== CatBoost with Fold 1/2 =========\n--------------------- Fold 2/2 -------------------\nTrain dates: from day 1550 to 1599 (50 days)\n--------------------------------------------------\n============== LightGBM with Fold 2/2 =========\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.767759 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19234\n[LightGBM] [Info] Number of data points in the train set: 1855656, number of used features: 79\n[LightGBM] [Info] Start training from score 0.000357\n============== XGBoost with Fold 2/2 =========\n============== CatBoost with Fold 2/2 =========\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"models.clear()\nfor fold, train_dates in enumerate(folds, start=1):\n        for model_name in model_dict.keys():\n            model = joblib.load(f\"models/{model_name}_{fold}.model\")\n            models.append((model_name, fold, model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:15:08.418896Z","iopub.execute_input":"2025-12-01T17:15:08.419087Z","iopub.status.idle":"2025-12-01T17:15:08.433442Z","shell.execute_reply.started":"2025-12-01T17:15:08.419072Z","shell.execute_reply":"2025-12-01T17:15:08.432913Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:15:08.435668Z","iopub.execute_input":"2025-12-01T17:15:08.435876Z","iopub.status.idle":"2025-12-01T17:15:08.458360Z","shell.execute_reply.started":"2025-12-01T17:15:08.435859Z","shell.execute_reply":"2025-12-01T17:15:08.457639Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[('LightGBM', 1, LGBMRegressor(n_estimators=50)),\n ('XGBoost',\n  1,\n  XGBRegressor(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=None, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=50, n_jobs=None,\n               num_parallel_tree=None, random_state=None, ...)),\n ('CatBoost', 1, <catboost.core.CatBoostRegressor at 0x7fcc92be7c10>),\n ('LightGBM', 2, LGBMRegressor(n_estimators=50)),\n ('XGBoost',\n  2,\n  XGBRegressor(base_score=None, booster=None, callbacks=None,\n               colsample_bylevel=None, colsample_bynode=None,\n               colsample_bytree=None, device=None, early_stopping_rounds=None,\n               enable_categorical=False, eval_metric=None, feature_types=None,\n               gamma=None, grow_policy=None, importance_type=None,\n               interaction_constraints=None, learning_rate=0.1, max_bin=None,\n               max_cat_threshold=None, max_cat_to_onehot=None,\n               max_delta_step=None, max_depth=None, max_leaves=None,\n               min_child_weight=None, missing=nan, monotone_constraints=None,\n               multi_strategy=None, n_estimators=50, n_jobs=None,\n               num_parallel_tree=None, random_state=None, ...)),\n ('CatBoost', 2, <catboost.core.CatBoostRegressor at 0x7fcc933f0f50>)]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# ========================================\n# Prediction Using the Ensemble of Models\n# ========================================\n\nlags_: pl.DataFrame | None = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame:\n    \"\"\"Make a prediction using the ensemble of models.\"\"\"\n    global lags_\n    if lags is not None:\n        lags_ = lags\n\n    # Convert features to NumPy for model prediction\n    feat = test.select(feature_names).to_numpy()\n    \n    # Ensemble prediction (average over all models)\n    pred = np.mean([model.predict(feat) for model in models], axis=0)\n    \n    # Create Polars DataFrame for submission\n    predictions = pl.DataFrame({\n        'row_id': test['row_id'],\n        'responder_6': pred.astype(np.float32)\n    })\n    \n    # Assertions for safety\n    assert isinstance(predictions, pl.DataFrame)\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    assert len(predictions) == len(test)\n\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:15:08.459098Z","iopub.execute_input":"2025-12-01T17:15:08.459337Z","iopub.status.idle":"2025-12-01T17:15:08.465292Z","shell.execute_reply.started":"2025-12-01T17:15:08.459321Z","shell.execute_reply":"2025-12-01T17:15:08.464799Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet',\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===============================\n# Submission\n# ===============================\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    # If the competition is currently running on Kaggle\n    inference_server.serve()\n\nelif os.getenv('KAGGLE_IS_COMPETITION_ACTIVE'):\n    # If the competition is still active\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet',\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet',\n        )\n    )\n\nelse:\n    # After the competition has ended\n    test_df = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet')\n    lags_df = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet')\n    \n    # Use your previously defined predict() function\n    predictions = predict(test_df, lags_df)\n    print(predictions)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}