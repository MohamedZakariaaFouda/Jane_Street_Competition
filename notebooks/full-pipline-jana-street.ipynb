{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport gc\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-25T18:10:30.497449Z","iopub.execute_input":"2025-11-25T18:10:30.497746Z","iopub.status.idle":"2025-11-25T18:10:30.501712Z","shell.execute_reply.started":"2025-11-25T18:10:30.497723Z","shell.execute_reply":"2025-11-25T18:10:30.500992Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# use the Kaggle input directory\ntrain_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\n\n# Define the feature names based on the number of features (79 in this case)\nfeatures_names = [f\"feature_{i:02d}\"for i in range(79)]\n\n# Define the target \ntarget = 'responder_6'\n\n# Number of validation dates to use\nnum_vaild_dates = 98\n\n# Skip_dates\nskip_dates = 1400","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T18:10:31.164463Z","iopub.execute_input":"2025-11-25T18:10:31.164733Z","iopub.status.idle":"2025-11-25T18:10:31.168872Z","shell.execute_reply.started":"2025-11-25T18:10:31.164714Z","shell.execute_reply":"2025-11-25T18:10:31.168152Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============================\n# Reduce Memory Usage Function\n# ============================\ndef reduce_memory_usage(df,float16_as32=False):\n    start_mem = df.memory_usage().sum()/1024**2\n    print(f'df memory usage before reduce : {start_mem} MB')\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        # Skip non-numeric columns\n        if col_type.kind not in ['i','f']:\n            continue\n        \n        c_min = df[col].min()\n        c_max = df[col].max()\n\n        # Integer types\n        if col_type.kind in ['i']:\n            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n            else:\n                df[col] = df[col].astype(np.int64)\n\n        # Float types\n        else:\n            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float32 if float16_as32 else np.float16)\n            elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n        \n    end_mem = df.memory_usage().sum()/1024**2\n    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n    print(f\"Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T18:10:58.861461Z","iopub.execute_input":"2025-11-25T18:10:58.862173Z","iopub.status.idle":"2025-11-25T18:10:58.870106Z","shell.execute_reply.started":"2025-11-25T18:10:58.862146Z","shell.execute_reply":"2025-11-25T18:10:58.869314Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_parquet(train_path, filters=[('date_id','>=', skip_dates)])\ndf = reduce_memory_usage(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T18:10:59.673539Z","iopub.execute_input":"2025-11-25T18:10:59.674310Z","iopub.status.idle":"2025-11-25T18:11:18.363690Z","shell.execute_reply.started":"2025-11-25T18:10:59.674257Z","shell.execute_reply":"2025-11-25T18:11:18.362813Z"}},"outputs":[{"name":"stdout","text":"df memory usage before reduce : 3711.112632751465 MB\nMemory usage after optimization is: 1907.97 MB\nDecreased by 48.6%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# ===============================#\n#        SETTINGS\n# ===============================#\nSTART_TRAIN = 1400\nEND_TRAIN   = 1599\nVALID_START = 1600\nVALID_END   = 1698\nN_FOLDS     = 2\n\n# ===============================#\n#     LOAD DATA (Train + Final Valid)\n# ===============================#\ntrain_df = (\n    df[df[\"date_id\"].between(START_TRAIN, END_TRAIN)]\n    .sort_values(\"date_id\")\n    .reset_index(drop=True)\n)\n\nvalid_df = df[df[\"date_id\"].between(VALID_START, VALID_END)]\nX_valid, y_valid, w_valid = (\n    valid_df[features_names],\n    valid_df[\"responder_6\"],\n    valid_df[\"weight\"],\n)\n\n# ===============================#\n#     CREATE FOLDS FROM DATES\n# ===============================#\nall_dates = np.arange(START_TRAIN, END_TRAIN + 1)\nfolds = np.array_split(all_dates, N_FOLDS)   # ⭐ تقسيم نظيف جداً\n\n# ===============================#\n#     LOOP THROUGH FOLDS\n# ===============================#\nfor fold, train_dates in enumerate(folds, start=1):\n    \n    fold_df = train_df[train_df[\"date_id\"].isin(train_dates)]\n    \n    X_train = fold_df[features_names]\n    y_train = fold_df[\"responder_6\"]\n    w_train = fold_df[\"weight\"]\n\n    print(f\"Fold {fold}/{N_FOLDS}\")\n    print(f\"  Train dates: {train_dates.min()} → {train_dates.max()}  ({len(train_dates)} days)\")\n    print(f\"  Train rows : {len(fold_df):,}\")\n    print(f\"  Final Valid: 1600 → 1698  ({len(X_valid):,} rows)\")\n    print(\"-\" * 50)\n\n    # model.fit(X_train, y_train, sample_weight=w_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-25T18:59:28.386595Z","iopub.execute_input":"2025-11-25T18:59:28.387315Z","iopub.status.idle":"2025-11-25T18:59:41.090484Z","shell.execute_reply.started":"2025-11-25T18:59:28.387261Z","shell.execute_reply":"2025-11-25T18:59:41.089757Z"}},"outputs":[{"name":"stdout","text":"Fold 1/2\n  Train dates: 1400 → 1499  (100 days)\n  Train rows : 3,595,152\n  Final Valid: 1600 → 1698  (3,679,368 rows)\n--------------------------------------------------\nFold 2/2\n  Train dates: 1500 → 1599  (100 days)\n  Train rows : 3,718,088\n  Final Valid: 1600 → 1698  (3,679,368 rows)\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}