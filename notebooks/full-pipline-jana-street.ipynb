{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":84493,"databundleVersionId":11305158,"sourceType":"competition"},{"sourceId":669416,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":506904,"modelId":521644}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport polars as pl\nimport gc\nimport os\nimport joblib \nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport kaggle_evaluation.jane_street_inference_server","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:03:31.342256Z","iopub.execute_input":"2025-12-02T05:03:31.342646Z","iopub.status.idle":"2025-12-02T05:03:31.346875Z","shell.execute_reply.started":"2025-12-02T05:03:31.342620Z","shell.execute_reply":"2025-12-02T05:03:31.346110Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# use the Kaggle input directory\ntrain_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet'\n\n# Define the feature names based on the number of features (79 in this case)\nfeatures_names = [f\"feature_{i:02d}\"for i in range(79)]\n\n# Define the target \ntarget = 'responder_6'\n\n# Skip_dates\nskip_dates = 1400","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:00:55.189833Z","iopub.execute_input":"2025-12-02T04:00:55.190241Z","iopub.status.idle":"2025-12-02T04:00:55.194061Z","shell.execute_reply.started":"2025-12-02T04:00:55.190222Z","shell.execute_reply":"2025-12-02T04:00:55.193402Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ============================\n# Reduce Memory Usage Function\n# ============================\ndef reduce_memory_usage(df,float16_as32=False):\n    start_mem = df.memory_usage().sum()/1024**2\n    print(f'df memory usage before reduce : {start_mem} MB')\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        # Skip non-numeric columns\n        if col_type.kind not in ['i','f']:\n            continue\n        \n        c_min = df[col].min()\n        c_max = df[col].max()\n\n        # Integer types\n        if col_type.kind in ['i']:\n            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n            else:\n                df[col] = df[col].astype(np.int64)\n\n        # Float types\n        else:\n            if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float32 if float16_as32 else np.float16)\n            elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n        \n    end_mem = df.memory_usage().sum()/1024**2\n    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n    print(f\"Decreased by {(100 * (start_mem - end_mem) / start_mem):.1f}%\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:00:55.194802Z","iopub.execute_input":"2025-12-02T04:00:55.194993Z","iopub.status.idle":"2025-12-02T04:00:55.207183Z","shell.execute_reply.started":"2025-12-02T04:00:55.194978Z","shell.execute_reply":"2025-12-02T04:00:55.206567Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_parquet(train_path, filters=[('date_id','>=', skip_dates)])\ndf = reduce_memory_usage(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:00:55.208401Z","iopub.execute_input":"2025-12-02T04:00:55.208629Z","iopub.status.idle":"2025-12-02T04:01:09.417418Z","shell.execute_reply.started":"2025-12-02T04:00:55.208614Z","shell.execute_reply":"2025-12-02T04:01:09.416756Z"}},"outputs":[{"name":"stdout","text":"df memory usage before reduce : 3711.112632751465 MB\nMemory usage after optimization is: 1907.97 MB\nDecreased by 48.6%\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"START_TRAIN = 1500\nEND_TRAIN   = 1599\nVALID_START = 1650\nVALID_END   = 1698\nN_FOLDS     = 2\n\n# ===============================#\n#     LOAD DATA (Train + Final Valid)\n# ===============================#\ntrain_df = ( df[df[\"date_id\"].between(START_TRAIN, END_TRAIN)].sort_values(\"date_id\"))\n\nvalid_df = df[df[\"date_id\"].between(VALID_START, VALID_END)]\nX_valid = valid_df[features_names]\ny_valid = valid_df[target]\nw_valid =  valid_df[\"weight\"]\n# ===============================#\n#     CREATE FOLDS FROM DATES\n# ===============================#\nall_dates = np.arange(START_TRAIN, END_TRAIN+1)\nfolds = np.array_split(all_dates, N_FOLDS)   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:01:09.418126Z","iopub.execute_input":"2025-12-02T04:01:09.418386Z","iopub.status.idle":"2025-12-02T04:01:12.473725Z","shell.execute_reply.started":"2025-12-02T04:01:09.418366Z","shell.execute_reply":"2025-12-02T04:01:12.473036Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ============================\n#  Model Dictionary\n# ============================\nmodel_dict = {\n    \"LightGBM\": lambda: LGBMRegressor(n_estimators=50, learning_rate=0.1),\n    \"XGBoost\":  lambda: XGBRegressor(n_estimators=50, learning_rate=0.1,),\n    \"CatBoost\": lambda: CatBoostRegressor(iterations=50, learning_rate=0.1, verbose=False)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:01:12.474423Z","iopub.execute_input":"2025-12-02T04:01:12.474659Z","iopub.status.idle":"2025-12-02T04:01:12.479134Z","shell.execute_reply.started":"2025-12-02T04:01:12.474642Z","shell.execute_reply":"2025-12-02T04:01:12.478304Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ==========================\n#  Create models directory \n# ==========================\nos.makedirs(\"models\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:01:12.479905Z","iopub.execute_input":"2025-12-02T04:01:12.480147Z","iopub.status.idle":"2025-12-02T04:01:12.490066Z","shell.execute_reply.started":"2025-12-02T04:01:12.480127Z","shell.execute_reply":"2025-12-02T04:01:12.489403Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ===============================#\n#     LOOP THROUGH FOLDS\n# ===============================#\nmodels = []\n\nfor fold, train_dates in enumerate(folds, start=1):\n    print(f\"--------------------- Fold {fold}/{N_FOLDS} -------------------\")\n    print(f\"Train dates: from day {train_dates.min()} to {train_dates.max()} ({len(train_dates)} days)\")\n    print('-'*50)\n    \n    fold_df = train_df[train_df[\"date_id\"].isin(train_dates)]\n    X_train = fold_df[features_names]\n    y_train = fold_df[target]\n    w_train = fold_df[\"weight\"]\n\n    \n    for model_name, model_class in model_dict.items():\n        \n        print(f'============== {model_name} with Fold {fold}/{N_FOLDS} =========')\n        # create NEW model object for THIS fold\n        model = model_class()\n        model.fit(X_train, y_train, sample_weight=w_train)\n        # Save model\n        joblib.dump(model, f\"models/{model_name}_{fold}.model\")\n        \n        models.append((model_name, fold, model))\n\n    del X_train, y_train, w_train\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:01:12.491295Z","iopub.execute_input":"2025-12-02T04:01:12.491466Z","iopub.status.idle":"2025-12-02T04:04:36.319329Z","shell.execute_reply.started":"2025-12-02T04:01:12.491452Z","shell.execute_reply":"2025-12-02T04:04:36.318739Z"}},"outputs":[{"name":"stdout","text":"--------------------- Fold 1/2 -------------------\nTrain dates: from day 1500 to 1549 (50 days)\n--------------------------------------------------\n============== LightGBM with Fold 1/2 =========\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.774422 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19236\n[LightGBM] [Info] Number of data points in the train set: 1862432, number of used features: 79\n[LightGBM] [Info] Start training from score -0.011091\n============== XGBoost with Fold 1/2 =========\n============== CatBoost with Fold 1/2 =========\n--------------------- Fold 2/2 -------------------\nTrain dates: from day 1550 to 1599 (50 days)\n--------------------------------------------------\n============== LightGBM with Fold 2/2 =========\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.745957 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 19234\n[LightGBM] [Info] Number of data points in the train set: 1855656, number of used features: 79\n[LightGBM] [Info] Start training from score 0.000357\n============== XGBoost with Fold 2/2 =========\n============== CatBoost with Fold 2/2 =========\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ======================\n# Load Pretrained model \n# ======================\n'''\nmodels_path ='/kaggle/input/models/scikitlearn/default/1/models'\nfor file in os.listdir(models_path):\n    if file.endswith(\".model\"):\n        model = joblib.load(os.path.join(models_path, file))\n        models.append(model)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:54:09.549593Z","iopub.execute_input":"2025-12-02T04:54:09.549853Z","iopub.status.idle":"2025-12-02T04:54:09.570400Z","shell.execute_reply.started":"2025-12-02T04:54:09.549835Z","shell.execute_reply":"2025-12-02T04:54:09.569583Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# ========================================\n# Prediction Using the Ensemble of Models\n# ========================================\n\nlags_: pl.DataFrame | None = None\n\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame:\n    \"\"\"Make a prediction using the ensemble of models.\"\"\"\n    global lags_\n    if lags is not None:\n        lags_ = lags\n\n    # Convert features to NumPy for model prediction\n    feat = test.select(features_names).to_numpy()\n    \n    # Ensemble prediction (average over all models)\n    pred = np.mean([model.predict(feat) for model in models], axis=0)\n    \n    # Create Polars DataFrame for submission\n    predictions = pl.DataFrame({\n        'row_id': test['row_id'],\n        'responder_6': pred.astype(np.float32)\n    })\n    \n    # Assertions for safety\n    assert isinstance(predictions, pl.DataFrame)\n    assert list(predictions.columns) == ['row_id', 'responder_6']\n    assert len(predictions) == len(test)\n\n    return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T04:07:47.692655Z","iopub.execute_input":"2025-12-02T04:07:47.693308Z","iopub.status.idle":"2025-12-02T04:07:47.698383Z","shell.execute_reply.started":"2025-12-02T04:07:47.693283Z","shell.execute_reply":"2025-12-02T04:07:47.697685Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# ===============\n# Submission\n# ===============\ninference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    # If the competition is currently running on Kaggle\n    inference_server.serve()\n\nelif os.getenv('KAGGLE_IS_COMPETITION_ACTIVE'):\n    # If the competition is still active\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet',\n            '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet',\n        )\n    )\n\nelse:\n    # After the competition has ended\n    test_df = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet')\n    lags_df = pl.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet')\n    \n    predictions = predict(test_df, lags_df)\n    print(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T05:03:37.205054Z","iopub.execute_input":"2025-12-02T05:03:37.205719Z","iopub.status.idle":"2025-12-02T05:03:37.277751Z","shell.execute_reply.started":"2025-12-02T05:03:37.205696Z","shell.execute_reply":"2025-12-02T05:03:37.277255Z"}},"outputs":[{"name":"stdout","text":"shape: (39, 2)\n┌────────┬─────────────┐\n│ row_id ┆ responder_6 │\n│ ---    ┆ ---         │\n│ i64    ┆ f32         │\n╞════════╪═════════════╡\n│ 0      ┆ 0.095125    │\n│ 1      ┆ 0.095125    │\n│ 2      ┆ 0.095125    │\n│ 3      ┆ 0.095125    │\n│ 4      ┆ 0.095125    │\n│ …      ┆ …           │\n│ 34     ┆ 0.095125    │\n│ 35     ┆ 0.095125    │\n│ 36     ┆ 0.110156    │\n│ 37     ┆ 0.095125    │\n│ 38     ┆ 0.095125    │\n└────────┴─────────────┘\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}